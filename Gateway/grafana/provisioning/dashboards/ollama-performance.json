{
  "id": null,
  "uid": "ollama-perf-full",
  "title": "Ollama Model Performance (Full)",
  "timezone": "browser",
  "schemaVersion": 36,
  "version": 1,
  "refresh": "5s",
  "panels": [
    {
      "type": "stat",
      "title": "Total Requests",
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(ollama_requests_total)",
          "legendFormat": "All Models"
        }
      ],
      "gridPos": { "x": 0, "y": 0, "w": 6, "h": 4 }
    },
    {
      "type": "stat",
      "title": "Tokens Per Second",
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "rate(ollama_tokens_per_second_sum[5m]) / rate(ollama_tokens_per_second_count[5m])",
          "legendFormat": "{{model}}"
        }
      ],
      "gridPos": { "x": 6, "y": 0, "w": 6, "h": 4 }
    },
    {
      "type": "graph",
      "title": "Requests by Model",
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum by (model) (ollama_requests_total)",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "drawStyle": "line"
        },
        "overrides": []
      },
      "gridPos": { "x": 0, "y": 4, "w": 12, "h": 6 }
    },
    {
      "type": "graph",
      "title": "Response Duration (seconds)",
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "rate(ollama_response_seconds_sum[5m]) / rate(ollama_response_seconds_count[5m])",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "drawStyle": "line"
        },
        "overrides": []
      },
      "gridPos": { "x": 0, "y": 10, "w": 12, "h": 6 }
    },
    {
      "type": "graph",
      "title": "Model Load Duration (seconds)",
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "rate(ollama_load_duration_seconds_sum[5m]) / rate(ollama_load_duration_seconds_count[5m])",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "drawStyle": "line"
        },
        "overrides": []
      },
      "gridPos": { "x": 0, "y": 16, "w": 12, "h": 6 }
    },
    {
      "type": "graph",
      "title": "Prompt Eval Duration (seconds)",
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "rate(ollama_prompt_eval_duration_seconds_sum[5m]) / rate(ollama_prompt_eval_duration_seconds_count[5m])",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "drawStyle": "line"
        },
        "overrides": []
      },
      "gridPos": { "x": 0, "y": 22, "w": 12, "h": 6 }
    },
    {
      "type": "graph",
      "title": "Generation Duration (seconds)",
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "rate(ollama_eval_duration_seconds_sum[5m]) / rate(ollama_eval_duration_seconds_count[5m])",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "drawStyle": "line"
        },
        "overrides": []
      },
      "gridPos": { "x": 0, "y": 28, "w": 12, "h": 6 }
    },
    {
      "type": "graph",
      "title": "Tokens Processed (prompt)",
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum by (model) (ollama_tokens_processed_total)",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "drawStyle": "line"
        },
        "overrides": []
      },
      "gridPos": { "x": 0, "y": 34, "w": 12, "h": 6 }
    },
    {
      "type": "graph",
      "title": "Tokens Generated (response)",
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum by (model) (ollama_tokens_generated_total)",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "drawStyle": "line"
        },
        "overrides": []
      },
      "gridPos": { "x": 0, "y": 40, "w": 12, "h": 6 }
    }
  ]
}
